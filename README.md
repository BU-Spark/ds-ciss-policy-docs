# TEMPLATE-base-repo

Create a new branch from dev, add changes on the new branch you just created.

Open a Pull Request to dev. Add your PM and TPM as reviewers. 

At the end of the semester during project wrap up open a final Pull Request to main from dev branch.

# Guidelines to convert metadata to dataframes

Before you run the code, please download and unzip the "Regulatory Statute Documents Set 1", "Regulatory Statute Documents Set 2", "Regulatory Statute Documents Set 3", "Mapping.xlsx" (save to csv file), and "policies.bkp.db" from the google drive and put them into the "data" folder within src folder.

Navigate to the src folder and run the following command:

    python load_data.py

It will result following files:
    src
    ├── data
    │   ├── all_documents (generated by load_data.py)
    │   ├── Regulatory Statute Documents Set 1 (download from google drive)
    │   |   ├── all_files (generated by load_data.py)
    │   |   ├── all metadata files (zip or txt)
    │   │── Regulatory Statute Documents Set 2 (download from google drive)
    │   |   ├── all_files (generated by load_data.py)
    │   |   ├── all metadata files (zip or txt)
    │   │── Regulatory Statute Documents Set 3 (download from google drive)
    │   |   ├── all_files (generated by load_data.py)
    │   |   ├── all metadata files (zip or txt)
    │   │—— data_error_log.txt (generated by load_data.py)
    │   │—— policies.bkp.db (genrate by web scraping)
    │   │—— Mapping.csv (download from google drive)
    │   │—— text_data.parquet (generated by load_data.py)

"all_documents": the final folder that contains all the documents in .txt form or .docx form.
"Regulatory Statute Documents Set: is files that unzip from the file download from the google drive.
"all_files": the intermidia folder that contains all files that in correponding Regulatory Statute Documents Set. 
"data_error_log.txt": the name of zip files that are not able to unzip.
"policies.bkp.db": the database that contains all the policy lables.
"Mapping.csv": store the hireachy structure of the policy labels, downlaoding from google drive.
"text_data.parquet": the final dataframe of all policy content (without labels).

The load_data.py will:
    First run iterate through all "Regulatory Statute Documents Set" folder, and extract all files and copy them into "all_files";

    Then it will iterate through all "all_files" folder, and unzip all files and move the unzip file them into "all_documents";

    Next, it will iterate through all "all_documents" folder, and extract all files and copy them into "all_documents" and convert them into .txt files.

    Finally, it will form a pandas dataframe and save it as .parquet file, names "text_data.parquet" in the "data" folder.

# Guidelines to Category Mapping

Since the content is Chinese, everytime we read text_data.parquet should call following function:

    # change path correspondingly
    from src.utils import encode_df 
    df = encode_df(pd.read_parquet('path_to_data/text_data.parquet', engine='pyarrow'),'content')

Our policy labels and texts are stored seperatlly (label is "policies.bkp.db" and text data is "text_data.parquet"), to generate a dataframe that contains both policy labels and texts, we should call following function:

    # change path correspondingly
    from src.load_data import generate_label_data
    df_path = "path_to_data/text_data.parquet"
    db_path = "path_to_data/policies.bkp.db"
    df_text_label = generate_label_data(df_path, db_path)
    # you can save df_text_label as .parquet or .csv file for further use

Given the mapping csv and the label, we can generate the path of the policy label, we should call following function:

    # change path correspondingly
    from categorize import read_csv_data, calulate_level_from_label
    mapping_path = "path_to_data/Mapping.csv"
    df_label = read_csv_data("data/Mapping.csv")
    l1, l2, l3, l4 = calulate_level_from_label(df_label,"name_of_label")
    # if no l3 or l4, it will return None
    # example: input:"律师业务" -> output: '法律与司法', '律师', '律师业务', None
    # if "name_of_label" don't appear in mapping csv, it will raise ValueError