{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ender_yang/Desktop/Spark/ds-ciss-policy-docs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/ender_yang/Desktop/Spark/ds-ciss-policy-docs'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd ..\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import numpy as np\n",
    "from lbl2vec import Lbl2TransformerVec\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from src.categories import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('src/data/all_files.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>海南省交通运输厅关于行政规范性文件清理结果</td>\n",
       "      <td>【法宝引证码】 CLI.12.5647676\\n原文链接：https://www.p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>重庆市国土房管局关于同意延长北碚区山水香庭</td>\n",
       "      <td>【法宝引证码】 CLI.12.1300415\\n原文链接：https://www.p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>甘肃省人力资源和社会保障厅、中国银保监会甘</td>\n",
       "      <td>【法宝引证码】 CLI.12.5608533\\n原文链接：https://www.p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>银川市人民政府关于公布政府规范性文件目录的</td>\n",
       "      <td>【法宝引证码】 CLI.12.469612\\n原文链接：https://www.pk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>三亚市人民政府办公室关于三亚市海棠湾6号污</td>\n",
       "      <td>【法宝引证码】 CLI.12.5472959\\n原文链接：https://www.p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               file_name                                            content\n",
       "0  海南省交通运输厅关于行政规范性文件清理结果      【法宝引证码】 CLI.12.5647676\\n原文链接：https://www.p...\n",
       "1  重庆市国土房管局关于同意延长北碚区山水香庭      【法宝引证码】 CLI.12.1300415\\n原文链接：https://www.p...\n",
       "2  甘肃省人力资源和社会保障厅、中国银保监会甘      【法宝引证码】 CLI.12.5608533\\n原文链接：https://www.p...\n",
       "3  银川市人民政府关于公布政府规范性文件目录的      【法宝引证码】 CLI.12.469612\\n原文链接：https://www.pk...\n",
       "4  三亚市人民政府办公室关于三亚市海棠湾6号污      【法宝引证码】 CLI.12.5472959\\n原文链接：https://www.p..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "for i in range(len(df)):\n",
    "    documents.append(df.iloc[i]['content'].split('.html\\n')[1].split('\\n')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = documents[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['海南省交通运输厅关于行政规范性文件清理结果的通报',\n",
       " '重庆市国土房管局关于同意延长北碚区山水香庭安置房项目行政确认有效期的通知',\n",
       " '甘肃省人力资源和社会保障厅、中国银保监会甘肃监管局关于进一步做好农民工工资保证金以工程保证保险替代工作的通知',\n",
       " '银川市人民政府关于公布政府规范性文件目录的通知',\n",
       " '三亚市人民政府办公室关于三亚市海棠湾6号污水提升泵站工程项目土地调查有关事项的通知',\n",
       " '甘肃省人民政府办公厅关于印发甘肃省产业扶贫专项贷款工程实施意见的通知',\n",
       " '海南省人民政府办公厅转发省文化广电出版体育厅等部门关于推动海南省动漫产业发展实施意见的通知',\n",
       " '海南省商务厅外贸处关于参加海峡两岸(泉州)农产品采购订货会的通知',\n",
       " '银川市建设局关于印发《银川市建筑施工安全质量标准化示范工程评审办法》的通知',\n",
       " '财政部新疆专员办关于审核2010棉花年度出疆棉移库费用补贴有关情况的通知(二)']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at thunlp/Lawformer were not used when initializing LongformerModel: ['lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing LongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerModel were not initialized from the model checkpoint at thunlp/Lawformer and are newly initialized: ['longformer.pooler.dense.bias', 'longformer.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "transformer_model = AutoModel.from_pretrained('bert-base-chinese')\n",
    "\n",
    "tokenizer_law = AutoTokenizer.from_pretrained(\"thunlp/Lawformer\")\n",
    "model_law = AutoModel.from_pretrained(\"thunlp/Lawformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_embedding(text):\n",
    "    inputs = tokenizer_law(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    # Get embeddings from BERT model\n",
    "    with torch.no_grad():\n",
    "        outputs = model_law(**inputs)\n",
    "    # Use mean pooling to get a single vector for the entire text\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    return embeddings.squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = get_l1()\n",
    "label_keywords = []\n",
    "for label in labels:\n",
    "    label_keywords.append(get_l2(label))\n",
    "    \n",
    "doc_embeddings = [get_bert_embedding(doc) for doc in documents]\n",
    "\n",
    "label_embeddings = [get_bert_embedding(label) for label in labels]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['农业', '林业', '牧业', '渔业', '土地', '水利', '资源', '能源', '地质矿产', '环境保护'],\n",
       " ['改革开放',\n",
       "  '统计',\n",
       "  '国有资产',\n",
       "  '财政',\n",
       "  '税收',\n",
       "  '财务',\n",
       "  '会计',\n",
       "  '审计',\n",
       "  '价格',\n",
       "  '企业',\n",
       "  '对外经贸',\n",
       "  '商贸物资',\n",
       "  '特区',\n",
       "  '开发区',\n",
       "  '外商投资企业',\n",
       "  '个体经济',\n",
       "  '房地产',\n",
       "  '测绘',\n",
       "  '咨询'],\n",
       " ['银行', '外汇', '票据', '证券', '租赁', '期货', '保险', '金融综合'],\n",
       " ['宪法',\n",
       "  '国家机关',\n",
       "  '机关工作',\n",
       "  '法制工作',\n",
       "  '律师',\n",
       "  '公证',\n",
       "  '民法',\n",
       "  '合同',\n",
       "  '知识产权',\n",
       "  '反不正当竞争',\n",
       "  '婚姻赡养收养继承',\n",
       "  '刑法',\n",
       "  '民事诉讼',\n",
       "  '经济审判',\n",
       "  '行政诉讼',\n",
       "  '刑事诉讼',\n",
       "  '劳改劳教监所狱政',\n",
       "  '司法协助',\n",
       "  '检察业务'],\n",
       " ['民政', '劳动工会', '人事规定', '调解与仲裁', '地震', '教育', '体育'],\n",
       " ['科技', '语言文字', '文物文史', '文化', '旅游', '广告'],\n",
       " ['卫生', '人口与计划生育', '商品检验与动植物检疫'],\n",
       " ['民族事务', '华侨事务', '港澳事务', '台湾事务', '宗教事务'],\n",
       " ['建设业', '工业管理', '标准化管理和认证认可', '计量', '质量管理和监督', '工商管理'],\n",
       " ['交通运输', '仓储', '邮政电讯'],\n",
       " ['海关', '社会监控', '公安', '国家安全', '外交外事', '军事']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_keywords\n",
    "\n",
    "# flatten 2d list to 1d\n",
    "label_keywords = [item for sublist in label_keywords for item in sublist]\n",
    "len(label_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_embeddings_list = []\n",
    "for keywords in label_keywords:\n",
    "    keywords_embeddings = get_bert_embedding(keywords)\n",
    "    keywords_embeddings_list.append(keywords_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(keywords_embeddings_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most similar label is 国家机关 with similarity score 0.6679660677909851\n",
      "The most similar label is 国家机关 with similarity score 0.6577949523925781\n",
      "The most similar label is 质量管理和监督 with similarity score 0.664229154586792\n",
      "The most similar label is 国家机关 with similarity score 0.6580724716186523\n",
      "The most similar label is 港澳事务 with similarity score 0.673235297203064\n",
      "The most similar label is 国家机关 with similarity score 0.6501578092575073\n",
      "The most similar label is 国家机关 with similarity score 0.6497042179107666\n",
      "The most similar label is 港澳事务 with similarity score 0.6966918706893921\n",
      "The most similar label is 质量管理和监督 with similarity score 0.6757918000221252\n",
      "The most similar label is 国家机关 with similarity score 0.7018440961837769\n"
     ]
    }
   ],
   "source": [
    "for doc_emb in doc_embeddings:\n",
    "    # calcualte similarity between each document and each label\n",
    "    similarity = []\n",
    "    for i, keyword_emb in enumerate(keywords_embeddings_list):\n",
    "        similarity.append(np.dot(doc_emb, keyword_emb)/(np.linalg.norm(doc_emb)*np.linalg.norm(keyword_emb)))\n",
    "    print(f'The most similar label is {label_keywords[np.argmax(similarity)]} with similarity score {np.max(similarity)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 12:45:00,238 - Lbl2TransformerVec - INFO - Compute keyword embeddings\n",
      "2024-02-26 12:45:00,238 - Lbl2TransformerVec - INFO - Compute keyword embeddings\n",
      "2024-02-26 12:45:04,707 - Lbl2TransformerVec - INFO - Compute document embeddings\n",
      "2024-02-26 12:45:04,707 - Lbl2TransformerVec - INFO - Compute document embeddings\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m Lbl2TransformerVec(transformer_model\u001b[38;5;241m=\u001b[39mtransformer_model, keywords_list\u001b[38;5;241m=\u001b[39mlabel_keywords,\n\u001b[1;32m      2\u001b[0m                            documents\u001b[38;5;241m=\u001b[39mdocuments)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/lbl2vec/lbl2transformervec.py:255\u001b[0m, in \u001b[0;36mLbl2TransformerVec.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m     distributed_transformer_embedding \u001b[38;5;241m=\u001b[39m ray\u001b[38;5;241m.\u001b[39mremote(transformer_embedding)\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;66;03m# embed documents with chosen transformer model\u001b[39;00m\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdocuments[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdoc_vec\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m ray\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m--> 255\u001b[0m         [distributed_transformer_embedding\u001b[38;5;241m.\u001b[39mremote(model\u001b[38;5;241m=\u001b[39mtransformer_model_id, document\u001b[38;5;241m=\u001b[39mdoc,\n\u001b[1;32m    256\u001b[0m                                                   device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m), tokenizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer) \u001b[38;5;28;01mfor\u001b[39;00m\n\u001b[1;32m    257\u001b[0m          doc \u001b[38;5;129;01min\u001b[39;00m\n\u001b[1;32m    258\u001b[0m          \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdocuments[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdoc\u001b[39m\u001b[38;5;124m'\u001b[39m])])\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    260\u001b[0m     ray\u001b[38;5;241m.\u001b[39mshutdown()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/lbl2vec/lbl2transformervec.py:255\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    252\u001b[0m     distributed_transformer_embedding \u001b[38;5;241m=\u001b[39m ray\u001b[38;5;241m.\u001b[39mremote(transformer_embedding)\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;66;03m# embed documents with chosen transformer model\u001b[39;00m\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdocuments[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdoc_vec\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m ray\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m--> 255\u001b[0m         [\u001b[43mdistributed_transformer_embedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremote\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformer_model_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocument\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m\n\u001b[1;32m    257\u001b[0m          doc \u001b[38;5;129;01min\u001b[39;00m\n\u001b[1;32m    258\u001b[0m          \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdocuments[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdoc\u001b[39m\u001b[38;5;124m'\u001b[39m])])\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    260\u001b[0m     ray\u001b[38;5;241m.\u001b[39mshutdown()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/ray/remote_function.py:139\u001b[0m, in \u001b[0;36mRemoteFunction.__init__.<locals>._remote_proxy\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_remote_proxy\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_remote\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_default_options\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/ray/_private/auto_init_hook.py:22\u001b[0m, in \u001b[0;36mwrap_auto_init.<locals>.auto_init_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mauto_init_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     21\u001b[0m     auto_init_ray()\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/ray/util/tracing/tracing_helper.py:310\u001b[0m, in \u001b[0;36m_tracing_task_invocation.<locals>._invocation_remote_span\u001b[0;34m(self, args, kwargs, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_ray_trace_ctx\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_ray_trace_ctx\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs\n\u001b[1;32m    313\u001b[0m tracer \u001b[38;5;241m=\u001b[39m _opentelemetry\u001b[38;5;241m.\u001b[39mtrace\u001b[38;5;241m.\u001b[39mget_tracer(\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/ray/remote_function.py:460\u001b[0m, in \u001b[0;36mRemoteFunction._remote\u001b[0;34m(self, args, kwargs, **task_options)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decorator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m     invocation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decorator(invocation)\n\u001b[0;32m--> 460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minvocation\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/ray/remote_function.py:428\u001b[0m, in \u001b[0;36mRemoteFunction._remote.<locals>.invocation\u001b[0;34m(args, kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m worker\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m ray\u001b[38;5;241m.\u001b[39m_private\u001b[38;5;241m.\u001b[39mworker\u001b[38;5;241m.\u001b[39mLOCAL_MODE:\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    426\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_cross_language\n\u001b[1;32m    427\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCross language remote function cannot be executed locally.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 428\u001b[0m object_refs \u001b[38;5;241m=\u001b[39m \u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore_worker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit_task\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_language\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_function_descriptor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlist_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_returns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry_exception_allowlist\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduling_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdebugger_breakpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserialized_runtime_env_info\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerator_backpressure_num_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;66;03m# Reset worker's debug context from the last \"remote\" command\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;66;03m# (which applies only to this .remote call).\u001b[39;00m\n\u001b[1;32m    445\u001b[0m worker\u001b[38;5;241m.\u001b[39mdebugger_breakpoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:3778\u001b[0m, in \u001b[0;36mray._raylet.CoreWorker.submit_task\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:3782\u001b[0m, in \u001b[0;36mray._raylet.CoreWorker.submit_task\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:855\u001b[0m, in \u001b[0;36mray._raylet.prepare_args_and_increment_put_refs\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:949\u001b[0m, in \u001b[0;36mray._raylet.prepare_args_internal\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:3537\u001b[0m, in \u001b[0;36mray._raylet.CoreWorker.put_serialized_object_and_increment_local_ref\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Lbl2TransformerVec(transformer_model=transformer_model, keywords_list=label_keywords,\n",
    "                           documents=documents)\n",
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 12:22:52,442 - Lbl2TransformerVec - INFO - Get document embeddings from model\n",
      "2024-02-26 12:22:52,445 - Lbl2TransformerVec - INFO - Calculate document<->label similarities\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_key</th>\n",
       "      <th>most_similar_label</th>\n",
       "      <th>highest_similarity_score</th>\n",
       "      <th>label_0</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "      <th>label_4</th>\n",
       "      <th>label_5</th>\n",
       "      <th>label_6</th>\n",
       "      <th>label_7</th>\n",
       "      <th>label_8</th>\n",
       "      <th>label_9</th>\n",
       "      <th>label_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>label_0</td>\n",
       "      <td>0.787184</td>\n",
       "      <td>0.787184</td>\n",
       "      <td>0.787184</td>\n",
       "      <td>0.787184</td>\n",
       "      <td>0.787184</td>\n",
       "      <td>0.787184</td>\n",
       "      <td>0.787184</td>\n",
       "      <td>0.787184</td>\n",
       "      <td>0.787184</td>\n",
       "      <td>0.787184</td>\n",
       "      <td>0.787184</td>\n",
       "      <td>0.787184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>label_0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>label_0</td>\n",
       "      <td>0.862197</td>\n",
       "      <td>0.862197</td>\n",
       "      <td>0.862197</td>\n",
       "      <td>0.862197</td>\n",
       "      <td>0.862197</td>\n",
       "      <td>0.862197</td>\n",
       "      <td>0.862197</td>\n",
       "      <td>0.862197</td>\n",
       "      <td>0.862197</td>\n",
       "      <td>0.862197</td>\n",
       "      <td>0.862197</td>\n",
       "      <td>0.862197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_key most_similar_label  highest_similarity_score   label_0   label_1  \\\n",
       "0        0            label_0                  0.787184  0.787184  0.787184   \n",
       "1        1            label_0                  1.000000  1.000000  1.000000   \n",
       "2        2            label_0                  0.862197  0.862197  0.862197   \n",
       "\n",
       "    label_2   label_3   label_4   label_5   label_6   label_7   label_8  \\\n",
       "0  0.787184  0.787184  0.787184  0.787184  0.787184  0.787184  0.787184   \n",
       "1  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000   \n",
       "2  0.862197  0.862197  0.862197  0.862197  0.862197  0.862197  0.862197   \n",
       "\n",
       "    label_9  label_10  \n",
       "0  0.787184  0.787184  \n",
       "1  1.000000  1.000000  \n",
       "2  0.862197  0.862197  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_model_docs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Lbl2TransformerVec' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m(test_sentences)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Output predictions\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, pred \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(predictions):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Lbl2TransformerVec' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_sentences)\n",
    "# Output predictions\n",
    "for i, pred in enumerate(predictions):\n",
    "    print(f\"Document {i+1} is predicted to be in category: {labels[pred]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
